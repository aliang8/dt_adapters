# In this experiment, we want to compare 
# model performance if we fine-tune an adapter module
# vs fine-tuning the full pretrained model. 

env_name: [
    pick-place-v2
]
target_return: [4000]
obj_randomization: [True]
use_adapters: [True, False]
seed: [0, 1]
exp_name: [adapter_vs_no_adapter]
log_to_wandb: [True]
num_warmup_rollouts: [50]
num_epochs: [200]
eval_every: [5]