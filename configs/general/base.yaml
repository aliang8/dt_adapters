# @package _group_

# shared configs 

# training config
seed: 1                                             # random seed
save_every: 10                                      # epochs between saving model checkpoints
eval_every: 1                                       # epochs between evaluating policy
num_steps_per_epoch: 50                             # number of gradient updates per online rollout
skip_first_eval: True                               # skip first evalution step
num_epochs: 100                                     # number of training epochs
batch_size: 64                                    

lr: 1e-4
weight_decay: 1e-4
alpha_lr: 1e-4                                      # learning rate for auto-tuning alpha
alpha_weight_decay: 1e-4                
warmup_steps: 10000                                 # warmup steps for scheduler

# logging
exp_name: test                        
log_to_wandb: False
log_outputs: True

# video configs
log_eval_videos: True
log_eval_videos_every: 10
fps: 20
image_height: 128
image_width: 128

# online_finetuning
online_training: False
model_ckpt_dir: /data/anthony/dt_adapters/outputs/
# model_ckpt_dir: 
load_from_ckpt: False

env_name: ""
obj_randomization: False

num_online_rollouts: 5
num_eval_rollouts: 10
train_on_offline_data: True
num_warmup_rollouts: 10
target_return: 500
scale: 100

num_data_workers: 1

use_adapters: False
adapter_task_name: ${env_name} # this should be the task name
adapter:
  config: pfeiffer+inv
  nonlinearity: none 
  reduction_factor: none