hidden_size: 768

state_dim: ${data.state_dim}
act_dim: ${data.act_dim}

state_encoder:
  hidden_size: ${model.hidden_size}
  state_dim: ${data.state_dim}
  act_dim: ${data.act_dim}
  pos_hand: 3
  obs_obj_max_len: 14
  gripper_distance_apart: 1
  goal_pos: 3
  state_keys: ['low_level', 'image']
  vision_backbone: clip                           # clip | resnet
  img_feat_dim: 768                               # output feature dim of pretrained vision model
  num_img_proj_layers: 3                          # number of mlp projection layers after vision encoder
  num_ll_enc_layers: 3                            # number of mlp projection layers after ll state encoder

  clip_feat_dim: 768 
  resnet_feat_dim: 1000
  image_keys: ${data.image_keys}

emb_state_separate: True
# num_layers: 3
stochastic: False
use_entropy: False
target_entropy: False
predict_return_dist: False

