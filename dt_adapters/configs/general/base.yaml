# shared configs 

# training config
seed: 1                                             # random seed
save_every: 10                                      # epochs between saving model checkpoints
eval_every: 0                                       # epochs between evaluating policy
num_eval_rollouts: 10                               # number of rollouts to evaluate policy
num_steps_per_epoch: 200                            # number of gradient updates per online rollout
skip_first_eval: False                              # skip first evalution step
num_epochs: 100                                     # number of training epochs
batch_size: 128                                   

# optimizer
optimizer: adamw
use_scheduler: False
lr: 1e-4                                            
weight_decay: 1e-4
warmup_steps: 10000
num_data_workers: 4                                 # number of workers for dataloader
use_lr_scheduler: False                             # use learning rate scheduler

# logging
project_name: dt-adapters
log_dir: /data/anthony/dt_adapters/results/         # root folder for experiment results
exp_name: test                                      # exp name, used for folder path and wandb group name
log_to_wandb: False                                 # should we log the metrics to wandb
log_outputs: False                                  # should we create a new folder and store exp output

# video configs
log_eval_videos: True                               # should we videos of eval rollouts
log_eval_videos_every: 10                           # number of epochs between every video save
fps: 20           

# resume 
load_from_ckpt: False                               # load pretrained model weights 
model_ckpt_dir:                                     # where to look for model checkpoint
resume_experiment: False                            # continue experiment
device: cuda